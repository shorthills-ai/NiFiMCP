import os
import sys
from pathlib import Path
import json
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from langchain_openai import AzureChatOpenAI
from pydantic import SecretStr
import datetime
from dotenv import load_dotenv
load_dotenv()

# Prepare today's date
today_str = datetime.date.today().strftime("%B %d, %Y")
week_str = f"{ (datetime.date.today() - datetime.timedelta(days=7)).strftime("%B %d, %Y") } - {today_str }"

base_dir = Path(__file__).resolve().parent
json_path = base_dir / "ai_news.json"

# Fetch recipients
recipients = os.getenv('AI_NEWS_RECIPIENTS')
recipients_data = json.loads(recipients)["toRecipients"]

# Initialize LLM
llm = AzureChatOpenAI(
        model="gpt-4o-mini",
        api_version='2024-12-01-preview',
        azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),
        api_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),
        )

def get_news_highlights(json_path):
    """Fetches AI news highlights from json file generated after scraping/searching for AI news."""
    highlights = []
    titles = []
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        return "Error: ai_news.json not found."
    except json.JSONDecodeError:
        return "Error: Could not decode ai_news.json."

    if "articles" in data and isinstance(data["articles"], list):
        for i, article in enumerate(data["articles"], 1):
            title = article.get("title", "N/A")
            summary = article.get("summary", "N/A")
            source_url = article.get("source_url", "N/A")
            
            highlight_entry = f"{i}. {title}\n\n"
            highlight_entry += f"‚ûî Summary: {summary}\n"
            highlight_entry += f"‚ûî Source URL: {source_url}\n"
            highlights.append(highlight_entry)
            titles.append(title)
            
    if not highlights:
        return "No articles found or articles are not in the expected format."
    
    highlights_joined = "\n\n".join(highlights)
    titles_joined = "\n".join(titles)

    return highlights_joined, titles_joined

def extract_takeaways_and_topics(titles_combined):
    """
    Generate takeaways and topics using Azure OpenAI.

    Parameters:
        input_content (list): List of scraped content strings.
        azure_deployment_name (str): Name of your Azure OpenAI deployment.
        azure_api_base (str): Your Azure OpenAI endpoint (e.g., 'https://<your-resource-name>.openai.azure.com/').
        azure_api_key (str): Your Azure OpenAI API key.
        azure_api_version (str): API version (default '2023-05-15').

    Returns:
        str: AI News Summary generated by the LLM.
    """


    # Build prompt
    prompt = f"""
        You are an AI assistant tasked with extracting content for AI news. Create key takeaways and topics found in the input content.

        Here is the scraped content:

        {titles_combined}

        Note: Provide a clear, concise, and structured output as per the format.
        Follow this output format:

‚úèÔ∏è Key Takeaways

- [Actionable takeaway or insight 1]  
- [Actionable takeaway or insight 2]  
- [Actionable takeaway or insight 3]


üóÇÔ∏è Topics Covered

- [List of topics or keywords extracted from the input]
"""

    messages = [
                SystemMessage(
                    content="You are an AI assistant tasked with creating an AI News Summary for employees in an organization."
                ),
                HumanMessage(content=prompt),
            ]

    response = llm.invoke(messages)

    # Extract response
    ai_news = response.content

    return ai_news


def generate_email_content(json_path):
    """
    Generates the email content with a summary of AI news.
    """
    highlights_joined,titles_joined = get_news_highlights(json_path)
    topic_takeaways = extract_takeaways_and_topics(titles_joined)

    email_body = f"""Hello all,
If you want to stay updated with the world of AI, dive into below AI news summary and follow-up quiz.

üß† Weekly Digest
Date: {week_str}


üåü Highlights

{highlights_joined}

{topic_takeaways}


-----------------------------------------------------------------

Best regards,
AI news
Shorthills AI
"""

    # Construct the dict object
    email_message = {
        "message": {
            "subject": "Weekly AI News & Quiz",
            "body": {
                "contentType": "Text",
                "content": email_body
            },
            "toRecipients": recipients_data
        }
    }

    # Serialize the whole structure as a valid JSON string
    template = json.dumps(email_message)

    return template


# ******************************************************************************************
# Usage: python get_ai_news_content.py <scraped_news_json_file>
# The JSON file should be the output from scrape_news.py
# ******************************************************************************************



if __name__ == "__main__":
    if len(sys.argv) == 2:
        json_path = Path(sys.argv[1])

    if not json_path.exists():
        sys.stderr.write(f"Expected news file not found at {json_path}\n")
        sys.exit(1)

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
    except Exception as e:
        sys.stderr.write(f"Error reading or parsing JSON: {str(e)}\n")
        sys.exit(1)


    email_body = generate_email_content(json_path)
    print(email_body)
