import os
import sys
from pathlib import Path
import json
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from langchain_openai import AzureChatOpenAI
from pydantic import SecretStr
import datetime
from dotenv import load_dotenv
load_dotenv()

# Prepare today's date
today_str = datetime.date.today().strftime("%B %d, %Y")
week_str = f"{ (datetime.date.today() - datetime.timedelta(days=7)).strftime("%B %d, %Y") } - {today_str }"

base_dir = Path(__file__).resolve().parent
json_path = base_dir / "ai_news.json"
repo_json_path = base_dir / "trending_repos.json"

# Fetch recipients
recipients = os.getenv('AI_NEWS_RECIPIENTS')
recipients_data = json.loads(recipients)["toRecipients"]

# Initialize LLM
llm = AzureChatOpenAI(
        model="gpt-4o-mini",
        api_version='2024-12-01-preview',
        azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),
        api_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),
        )

def get_news_highlights(json_path):
    """Fetches AI news highlights from json file generated after scraping/searching for AI news."""
    highlights = []
    titles = []
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        return "Error: ai_news.json not found."
    except json.JSONDecodeError:
        return "Error: Could not decode ai_news.json."

    if "articles" in data and isinstance(data["articles"], list):
        for i, article in enumerate(data["articles"], 1):
            title = article.get("title", "N/A")
            summary = article.get("summary", "N/A")
            source_url = article.get("source_url", "N/A")
            
            highlight_entry = f"<em>üóûÔ∏è{title}</em><br>"
            highlight_entry += f"‚ûî Summary: {summary}<br>"
            highlight_entry += f"‚ûî Source: <a href={source_url}>{source_url}</a><br><br>"
            highlights.append(highlight_entry)
            titles.append(title)
            
    if not highlights:
        return "No articles found or articles are not in the expected format."
    
    highlights_joined = "\n\n".join(highlights)
    titles_joined = "\n".join(titles)

    return highlights_joined, titles_joined

def extract_takeaways_and_topics(titles_combined):
    """
    Generate takeaways and topics using Azure OpenAI.

    Parameters:
        input_content (list): List of scraped content strings.
        azure_deployment_name (str): Name of your Azure OpenAI deployment.
        azure_api_base (str): Your Azure OpenAI endpoint (e.g., 'https://<your-resource-name>.openai.azure.com/').
        azure_api_key (str): Your Azure OpenAI API key.
        azure_api_version (str): API version (default '2023-05-15').

    Returns:
        str: AI News Summary generated by the LLM.
    """


    # Build prompt
    prompt = f"""
        You are an AI assistant tasked with extracting content for AI news. Create key takeaways and topics found in the input content.

        Here is the scraped content:

        {titles_combined}

        Note: Provide a clear, concise, and structured output as per the format.
        Follow this output format:

<h2>‚úèÔ∏è Key Takeaways</h2>
<p>
<ul>
<li> [Actionable takeaway or insight 1] </li>
<li> [Actionable takeaway or insight 2] </li>
<li> [Actionable takeaway or insight 3] </li>
</ul>
</p>

<h2>üóÇÔ∏è Topics Covered</h2>
<p>
<li>[List of topics or keywords extracted from the input]</li>
<p>
"""

    messages = [
                SystemMessage(
                    content="You are an AI assistant tasked with creating an AI News Summary for employees in an organization."
                ),
                HumanMessage(content=prompt),
            ]

    response = llm.invoke(messages)

    # Extract response
    ai_news = response.content

    return ai_news

def sort_highlights(highlights_joined):
    """
    Arranges the highlights into different sections based on topics.
    """
    prompt = f"""
You are an expert AI assistant tasked with curating an internal AI news digest for employees. Your goal is to make the news easy to understand by organizing it thematically.

You will be given a list of news highlights. Your task is to analyze these highlights and group them into logical sections based on recurring technologies, products, protocols, or major themes.

**Instructions:**

1.  **Identify Key Themes:** Read through all the highlights and identify the main subjects. Look for specific, recurring keywords that define a topic, such as "Model Context Protocol (MCP)", "A2A", "Google", "Openai", "Antropic", "Llama" or "AI Agents".
2.  **Create Section Headings:** Based on these themes, create clear and descriptive headings. Use html for the headings (e.g., '<h3>Model Context Protocol (MCP)</h3>'). The headings should be based on the specific technologies or products themselves.
3.  **Group the Highlights:** Place each original highlight under the most appropriate section heading.
4.  **Preserve Original Content:** Copy the highlights into the sections *exactly* as they are provided, including their original number, title, summary, and source URL. Do not alter, re-summarize, or re-number them.
5.  **Be Logical:** Group items that are clearly related. For example, all news about MCP servers under single MCP-related heading, all news from google models and tools under google, similarly for any other organization.
6.  **Handle Other News:** For highlights that don't fit into a specific, recurring technology group, create a broader category '<h3>AI Developments</h3>'.

Here are the news highlights you need to sort:

---
{highlights_joined}
---

Please provide the sorted and categorized list of highlights below. The final output should be only the categorized news with no extra text or backtick, ready for a newsletter.
"""

    messages = [
                # The SystemMessage sets the overall context for the LLM's persona.
                SystemMessage(
                    content="You are an AI assistant tasked with sorting AI News for employees in an organization. You produce well-structured, clean output in Markdown format."
                ),
                # The HumanMessage contains the detailed instructions and the data.
                HumanMessage(content=prompt),
            ]

    response = llm.invoke(messages)
    categorized_highlights = response.content   
    return categorized_highlights

def get_trending_repositories(repo_json_path):
    repositories = []
    try:
        with open(repo_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        return "Error: trending_repos.json not found."
    except json.JSONDecodeError:
        return "Error: Could not decode trending_repos.json."

    if "repos" in data and isinstance(data["repos"], list):
        for i, article in enumerate(data["repos"], 1):
            repo_name = article.get("repo_name", "N/A")
            description = article.get("description", "N/A")
            source_url = article.get("repo_url", "N/A")
            
            repo_entry = f"<em>üîó{repo_name}</em><br>"
            repo_entry += f"Description: {description}<br>"
            repo_entry += f"Source: <a href={source_url}>{source_url}</a><br><br>"
            repositories.append(repo_entry)

            
    if not repositories:
        return "No trending repos found."
    
    repositories_joined = "\n\n".join(repositories)

    return repositories_joined

def generate_email_content(json_path,repo_json_path):
    """
    Generates the email content with a summary of AI news.
    """
    highlights_joined,titles_joined = get_news_highlights(json_path)
    topic_takeaways = extract_takeaways_and_topics(titles_joined)

    categorized_highlights = sort_highlights(highlights_joined)

    # get trending repositories
    trending_repos = get_trending_repositories(repo_json_path)


    email_body = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';
            line-height: 1.6;
            color: #333333;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }}
        .container {{
            max-width: 680px;
            margin: 20px auto;
            padding: 25px;
            background-color: #ffffff;
            border-radius: 8px;
            border: 1px solid #dddddd;
        }}
        h2 {{
            font-size: 24px;
            color: #1a1a1a;
            margin-top: 10px;
            margin-bottom: 20px;
        }}
        h3 {{
            font-size: 20px;
            color: #1a1a1a;
            border-bottom: 2px solid #eeeeee;
            padding-bottom: 8px;
            margin-top: 30px;
        }}
        h4 {{
            font-size: 16px;
            font-weight: 600;
            color: #111;
            margin-bottom: 5px;
            margin-top: 20px;
        }}
        p {{
            margin: 0 0 10px 0;
        }}
        a {{
            color: #007bff;
            text-decoration: none;
        }}
        a:hover {{
            text-decoration: underline;
        }}
        ul {{
            padding-left: 25px;
            margin-top: 0;
        }}
        li {{
            margin-bottom: 8px;
        }}
        .summary, .source-link {{
            margin-left: 20px;
            font-size: 15px;
        }}
        .footer {{
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #cccccc;
            font-size: 14px;
            color: #555555;
        }}
    </style>
</head>
<body>
    <div class="container">
        <p>Hello all,</p>
        <p>If you want to stay updated with the world of AI, dive into the following headlines and news summary from around the globe.</p>

        <h2>üß† Daily Digest</h2>
        <p><strong>Date:</strong> {today_str}</p>

        <h2>üåü Highlights</h2>
        {categorized_highlights}

        {topic_takeaways}

        <br><br>
        <h2>üì¶ Trending repositories</h2>
        {trending_repos}

        <div class="footer">
            Best regards,<br>
            AI news<br>
            Shorthills AI
        </div>
    </div>
</body>
</html>"""


    # Construct the dict object
    email_message = {
        "message": {
            "subject": "Daily AI News",
            "body": {
                "contentType": "HTML",
                "content": email_body
            },
            "toRecipients": recipients_data
        }
    }

    # Serialize the whole structure as a valid JSON string
    template = json.dumps(email_message)

    return template


# ******************************************************************************************
# Usage: python get_ai_news_content.py <scraped_news_json_file>
# The JSON file should be the output from scrape_news.py
# ******************************************************************************************



if __name__ == "__main__":
    if len(sys.argv) == 2:
        json_path = Path(sys.argv[1])

    if not json_path.exists():
        sys.stderr.write(f"Expected news file not found at {json_path}\n")
        sys.exit(1)

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
    except Exception as e:
        sys.stderr.write(f"Error reading or parsing JSON: {str(e)}\n")
        sys.exit(1)


    email_body = generate_email_content(json_path,repo_json_path)
    print(email_body)
