import os
import sys
from pathlib import Path
import json
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from langchain_openai import AzureChatOpenAI
from pydantic import SecretStr
import datetime
from dotenv import load_dotenv
load_dotenv()

# Prepare today's date
today_str = datetime.date.today().strftime("%B %d, %Y")
week_str = f"{ (datetime.date.today() - datetime.timedelta(days=7)).strftime("%B %d, %Y") } - {today_str }"

base_dir = Path(__file__).resolve().parent
json_path = base_dir / "filtered_ai_news.json"
repo_json_path = base_dir / "trending_repos.json"

# Fetch recipients
recipients = os.getenv('AI_NEWS_RECIPIENTS')
recipients_data = json.loads(recipients)["toRecipients"]

# Initialize LLM
llm = AzureChatOpenAI(
        model="gpt-4o-mini",
        api_version='2024-12-01-preview',
        azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),
        api_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),
        )

def get_news_highlights(json_path):
    """Fetches AI news highlights from json file generated after scraping/searching for AI news."""
    highlights = []
    titles = []
    contents = []
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        return "Error: filtered_ai_news.json not found."
    except json.JSONDecodeError:
        return "Error: Could not decode filtered_ai_news.json."

    if "articles" in data and isinstance(data["articles"], list):
        for i, article in enumerate(data["articles"], 1):
            title = article.get("title", "N/A")
            source_url = article.get("source_url", "N/A")
            content = article.get("content", "N/A")
            
            highlight_entry = f"<a href={source_url}><em>üóûÔ∏è{title}</em></a><br>"
            highlight_entry += f"‚ûî {content}<br>"
            highlights.append(highlight_entry)
            titles.append(title)
            contents.append(content)
            
    if not highlights:
        return "No articles found or articles are not in the expected format."
    
    highlights_joined = "\n\n".join(highlights)
    titles_joined = "\n".join(titles)
    contents_joined = "\n".join(contents)

    return highlights_joined, titles_joined, contents_joined

def extract_takeaways_and_topics(titles_combined):
    """
    Generate takeaways and topics using Azure OpenAI.

    Parameters:
        input_content (list): List of scraped content strings.
        azure_deployment_name (str): Name of your Azure OpenAI deployment.
        azure_api_base (str): Your Azure OpenAI endpoint (e.g., 'https://<your-resource-name>.openai.azure.com/').
        azure_api_key (str): Your Azure OpenAI API key.
        azure_api_version (str): API version (default '2023-05-15').

    Returns:
        str: AI News Summary generated by the LLM.
    """


    # Build prompt
    prompt = f"""
        You are an AI assistant tasked with extracting content for AI news. Create key takeaways and topics found in the input content.

        Here is the scraped content:

        {titles_combined}

        Note: Provide a clear, concise, and structured output as per the format.
        Follow this output format:

<h2>‚úèÔ∏è Key Takeaways</h2>
<p>
<ul>
<li> [Actionable takeaway or insight 1] </li>
<li> [Actionable takeaway or insight 2] </li>
<li> [Actionable takeaway or insight 3] </li>
</ul>
</p>

<h2>üóÇÔ∏è Topics Covered</h2>
<p>
<li>[List of topics or keywords extracted from the input]</li>
<p>
"""

    messages = [
                SystemMessage(
                    content="You are an AI assistant tasked with creating an AI News Summary for employees in an organization."
                ),
                HumanMessage(content=prompt),
            ]

    response = llm.invoke(messages)

    # Extract response
    ai_news = response.content

    return ai_news

def sort_highlights(highlights_joined):
    """
    Arranges the highlights into different sections based on topics.
    """
    prompt = f"""
You will be given a list of news highlights. Your task is to analyze these highlights and group them into logical sections based on recurring technologies, products, protocols, or major themes.

**Instructions:**

1.  **Identify Key Themes:** Read through all the highlights and identify the main subjects. Look for specific, recurring keywords that define a topic, from one of "Model Context Protocol (MCP)", "A2A", "Google", "Openai", "Antropic", "Llama" or "AI Agents", "AI Tools".
2.  **Create Section Headings:** Based on these themes, create clear and descriptive headings. Use html for the headings (e.g., '<h3>Model Context Protocol (MCP)</h3>'). The headings should be based on the specific technologies or products themselves.
3.  **Group the Highlights:** Place each original highlight under the most appropriate section heading.
4.  **Preserve Original Content:** Copy the highlights into the sections *exactly* as they are provided, including the content, its style and structure. Do not alter, re-summarize, or number them.
5.  **Be Logical:** Group items that are clearly related. For example, all news about MCP servers under single MCP-related heading, all news from google models and tools under google, similarly for any other organization.
6.  **Handle Other News:** For highlights that don't fit into a specific, recurring technology group, create a broader category '<h3>AI Developments</h3>'.

Here are the news highlights you need to sort:

---
{highlights_joined}
---

Please provide the sorted and categorized list of highlights below. The final output should be only the categorized news with no extra text or backtick, ready for a newsletter"""

    messages = [
                # The SystemMessage sets the overall context for the LLM's persona.
                SystemMessage(
                    content="You are an AI assistant tasked with sorting AI News for employees in an organization. You produce well-structured, clean output in Markdown format."
                ),
                # The HumanMessage contains the detailed instructions and the data.
                HumanMessage(content=prompt),
            ]

    response = llm.invoke(messages)
    categorized_highlights = response.content   
    return categorized_highlights

def get_trending_repositories(repo_json_path):
    repositories = []
    try:
        with open(repo_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        return "Error: trending_repos.json not found."
    except json.JSONDecodeError:
        return "Error: Could not decode trending_repos.json."

    if "repos" in data and isinstance(data["repos"], list):
        for i, article in enumerate(data["repos"], 1):
            repo_name = article.get("repo_name", "N/A")
            description = article.get("description", "N/A")
            source_url = article.get("repo_url", "N/A")
            
            repo_entry = f"<em>üîó{repo_name}</em><br>"
            repo_entry += f"Description: {description}<br>"
            repo_entry += f"Source: <a href={source_url}>{source_url}</a><br><br>"
            repositories.append(repo_entry)

            
    if not repositories:
        return "No trending repos found."
    
    repositories_joined = "\n\n".join(repositories)

    return repositories_joined

def generate_quiz(ai_summary: str) -> tuple[str, dict]:
    """
    Generates an interactive HTML quiz with radio buttons based on the AI news summary.

    This function instructs an LLM to create a 10-question quiz in JSON format,
    then builds a self-contained HTML file with embedded CSS and JavaScript
    to provide immediate feedback to the user upon selecting a radio button.

    Args:
        ai_summary: A string containing the summarized content for the quiz.

    Returns:
        A tuple containing:
        - interactive_quiz (str): The full HTML code for the interactive quiz.
        - answer_key (dict): A dictionary mapping question numbers to correct answers (e.g., {1: 'A', 2: 'C'}).
    """
    
    # 1. Updated prompt to request JSON output with answers (remains the same)
    prompt = f"""
        You are an AI quiz generator specializing in creating interactive learning content.
        Your task is to create a quiz of 10 questions based on the provided content.

        For each question, provide the question text, 4 multiple-choice options (A, B, C, D),
        and identify the letter of the correct answer.

        **IMPORTANT**: Respond ONLY with a valid JSON object. The JSON should be a list of objects,
        where each object has the following keys:
        - "question": A string for the question text.
        - "options": An object with keys "A", "B", "C", "D".
        - "answer": A string representing the key of the correct option (e.g., "A").

        Do not include any other text, greetings, or explanations outside of the JSON object.

        Here is the summarized content:
        {ai_summary}

        Example JSON output format:
        [
            {{
                "question": "What is the capital of France?",
                "options": {{
                    "A": "Paris",
                    "B": "London",
                    "C": "Berlin",
                    "D": "Madrid"
                }},
                "answer": "A"
            }},
            {{
                "question": "What is the largest planet in our solar system?",
                "options": {{
                    "A": "Earth",
                    "B": "Mars",
                    "C": "Jupiter",
                    "D": "Saturn"
                }},
                "answer": "C"
            }}
        ]
    """
    
    messages = [
        SystemMessage(content="You are an AI quiz generator specializing in JSON output."),
        HumanMessage(content=prompt),
    ]
    response = llm.invoke(messages)
    llm_output = response.content
    cleaned_output = llm_output.replace("```json", "").replace("```", "").strip()

    try:
        quiz_data = json.loads(cleaned_output)
        # Save the valid quiz_data to quiz.json
        with open("quiz.json", "w", encoding="utf-8") as f:
            json.dump(quiz_data, f, ensure_ascii=False, indent=2)
    except json.JSONDecodeError:
        raise ValueError("The LLM did not return valid JSON. Please check the input and try again.")

def generate_email_content(json_path,repo_json_path):
    """
    Generates the email content with a summary of AI news.
    """
    highlights_joined,titles_joined, contents_joined = get_news_highlights(json_path)
    topic_takeaways = extract_takeaways_and_topics(titles_joined)

    categorized_highlights = sort_highlights(highlights_joined)

    # get trending repositories
    trending_repos = get_trending_repositories(repo_json_path)

    # generate quiz
    generate_quiz(contents_joined)
    # set quiz url
    quiz = "<a href=http://104.208.162.61:8002/>Click here</a>"


    email_body = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';
            line-height: 1.6;
            color: #333333;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }}
        .container {{
            max-width: 680px;
            margin: 20px auto;
            padding: 25px;
            background-color: #ffffff;
            border-radius: 8px;
            border: 1px solid #dddddd;
        }}
        h2 {{
            font-size: 24px;
            color: #1a1a1a;
            margin-top: 10px;
            margin-bottom: 20px;
        }}
        h3 {{
            font-size: 20px;
            color: #1a1a1a;
            border-bottom: 2px solid #eeeeee;
            padding-bottom: 8px;
            margin-top: 30px;
        }}
        h4 {{
            font-size: 16px;
            font-weight: 600;
            color: #111;
            margin-bottom: 5px;
            margin-top: 20px;
        }}
        p {{
            margin: 0 0 10px 0;
        }}
        a {{
            color: #007bff;
            text-decoration: none;
        }}
        a:hover {{
            text-decoration: underline;
        }}
        ul {{
            padding-left: 25px;
            margin-top: 0;
        }}
        li {{
            margin-bottom: 8px;
        }}
        .summary, .source-link {{
            margin-left: 20px;
            font-size: 15px;
        }}
        .footer {{
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #cccccc;
            font-size: 14px;
            color: #555555;
        }}
    </style>
</head>
<body>
    <div class="container">
        <p>Hello all,</p>
        <p>If you want to stay updated with the world of AI, dive into the following headlines and news summary from around the globe.</p>

        <h2>üß† Daily Digest</h2>
        <p><strong>Date:</strong> {today_str}</p>

        <h2>üåü Highlights</h2>
        {categorized_highlights}

        {topic_takeaways}

        <br><br>
        <h2>üì¶ Trending repositories</h2>
        {trending_repos}

        <br><br>
        <h3>üïíüß™ Quick Quiz</h3>
        {quiz}

        <div class="footer">
            Best regards,<br>
            AI news<br>
            Shorthills AI
        </div>
    </div>
</body>
</html>"""


    # Construct the dict object
    email_message = {
        "message": {
            "subject": "Daily AI News",
            "body": {
                "contentType": "HTML",
                "content": email_body
            },
            "toRecipients": recipients_data
        }
    }

    # Serialize the whole structure as a valid JSON string
    template = json.dumps(email_message)

    return template


# ******************************************************************************************
# Usage: python get_ai_news_content.py <scraped_news_json_file>
# The JSON file should be the output from scrape_news.py
# ******************************************************************************************



if __name__ == "__main__":
    if len(sys.argv) == 2:
        json_path = Path(sys.argv[1])

    if not json_path.exists():
        sys.stderr.write(f"Expected news file not found at {json_path}\n")
        sys.exit(1)

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
    except Exception as e:
        sys.stderr.write(f"Error reading or parsing JSON: {str(e)}\n")
        sys.exit(1)


    email_body = generate_email_content(json_path,repo_json_path)
    print(email_body)
